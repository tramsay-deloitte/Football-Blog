{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb39472",
   "metadata": {},
   "source": [
    "## Will a Wide Receiver be good in the NFL?\n",
    "\n",
    "I have many thoughts about how wide receivers can be projected coming out of college into the NFL.\n",
    "\n",
    "As a Patriots fan, I have seen many receivers drafted in the first or second round and have them get cut only a few years later. Although I don't expect any pity given the Super Bowls I remember so fondly, I also remember our last great drafted receiver being a quarterback from Kent State in the 7th round named Julian Edelman, and our more recent pretty good receiver being a Quarterback from NC State named Jakobi Meyers. Why did Bill have an easier time finding QBs converting to WRs than people that played WR their whole lives and are 99th percentile athletes? Blows my mind. \n",
    "\n",
    "We look back at the Nkeal Harry draft and wince at the fact that nearly every other first round pick was a hit AND some of the best receivers in the league were taken after him. DK Metcalf, AJ Brown, Deebo Samuel, Terry McLaurin... c'mon man. \n",
    "\n",
    "Given the fact that I feel it can't be THAT hard, I will be pooling together public data about these draft prospects and finding if data and relatively simple modeling strategy can predict whether a guy is going to be good before he's going to be good.\n",
    "\n",
    "As a data scientist and not a scout that's watching an athlete from the stands at the Senior Bowl, during their college season, or following their career closely in the NFL, I need to find some proxies to determine what gives a WR a hand up in the draft process and what determines success in the NFL.\n",
    "\n",
    "My first step is to determine a proxy for success in the NFL. Although not a perfect measurement, my metric will be APY as a % of Cap at Signing from [Over The Cap](https://overthecap.com/). Although we still need to account for the inflation of the WR market, this metric helps control for the changing salary cap while also representing how much a team is willing to invest in a player. We will specifically be looking at every players second contract to represent how well the prospect performed on their rookie deal to earn that second contract. Obviously players are overpaid or take pay cuts to play on a good team, we can figure that out later.\n",
    "\n",
    "My hypothesis is that elite receivers are usually 6'0 to 6'2 and around 195 to 210. My ideal receiver in my mind is someone that is 6'1 200 lbs with long arms (Yes, I'm basically just describing Justin Jefferson). Smaller will likely be easily pushed around on routes and can't play on all downs to block for running plays. Larger will likely not move well enough to get separation or yards after catch against NFL defenders and will become a contested catch merchant. \n",
    "\n",
    "<img src=\"https://patriotswire.usatoday.com/wp-content/uploads/sites/71/2024/08/USATSI_23983546.jpg?w=1000&h=600&crop=1\" alt=\"Jalynn Polk\" width=\"800\">\n",
    "\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "## [Sneak Peak at Results](#Lets-skip-to-the-good-part)\n",
    "\n",
    "## [Section 1. Import and Clean the data](#Section-1.-Import-and-Clean-the-data)\n",
    "- [Combine Data](#a.-Scrape-Combine-Data)\n",
    "\n",
    "- [Prospect Grades](#b.-Scrape-WR-Prospect-Grades)\n",
    "- [Second Contract Data](#c.-Scrape-Second-Contract-Data)\n",
    "- [College Receiving Stats](#d.-Scrape-Receiving-Stats)\n",
    "- [Join the data and make model variables](#e.-Join-the-data-and-make-model-variables)\n",
    "        \n",
    "## [Section 2. Multiple Linear Regression](#Section-2.-Build-The-Model)\n",
    "- [Build the Regression Model](##Section-2.-Build-The-Model)\n",
    "- [Predict APY as % of Cap for the Test Set](#Predict-APY-%-for-10-Receivers-that-got-large-contracts)\n",
    "        \n",
    "\n",
    "## [Section 3. Predict The Unseen Young Receivers](#Section-3.-Predict-Contracts-for-2021-through-2024-Draft-ClassesÂ¶)\n",
    "- [Final Results!](#The-Top-5-Predicted-Receivers-from-2021-through-2024:)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Lets skip to the good part\n",
    "\n",
    "If you scroll to the bottom of the notebook you will see the top rankings for wide receivers based on their college data. Here are the top results...\n",
    "\n",
    "# The Top 5 Predicted Receivers from 2021 through 2024:\n",
    "\n",
    "### 1. Jamarr Chase - 6.4%\n",
    "<img src=\"https://statico.profootballnetwork.com/wp-content/uploads/2024/11/07193200/jamarr-chase-net-worth-lifestyle-1920x1280.jpg\" alt=\"Jamarr Chase\" width=\"300\">\n",
    "\n",
    "\n",
    "\n",
    "### 2. Rome Odunze - 6.2%\n",
    "<img src=\"https://static.clubs.nfl.com/image/upload/t_person_squared_mobile/f_auto/v1725550057/bears/t3lmtlfbcktn3vlxd4bz.jpg\" alt=\"Rome Odunze\" width=\"300\">\n",
    "\n",
    "\n",
    "### 3. Jaxon Smith-Njigba - 5.9%\n",
    "<img src=\"https://images.seattletimes.com/wp-content/uploads/2023/09/09062023_1_141406.jpg?d=2040x1632\" alt=\"JSN\" width=\"300\">\n",
    "\n",
    "### 4. Malik Nabers - 5.7%\n",
    "<img src=\"https://images2.minutemediacdn.com/image/upload/c_crop,w_1599,h_899,x_0,y_0/c_fill,w_912,ar_16:9,f_auto,q_auto,g_auto/images/voltaxMediaLibrary/mmsport/si/01j8s0dny0qd3rwn3sea.jpg\" alt=\"Nabers\" width=\"300\">\n",
    "\n",
    "### 5. Jameson Williams - 5.5%\n",
    "<img src=\"https://static.clubs.nfl.com/image/upload/t_editorial_landscape_12_desktop/lions/llgjkaa0a7rd15qupozm\" alt=\"Jamo\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67f5e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806100aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the years\n",
    "college_years_list = ['2010','2011','2012','2013','2014','2015','2016','2017','2018', '2019']\n",
    "combine_years_list = ['2013','2014','2015','2016','2017','2018','2019', '2020']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58f2919",
   "metadata": {},
   "source": [
    "## Section 1. Import and Clean the data\n",
    "\n",
    "## a. Scrape Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e1a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_combine(years_list):\n",
    "    class_list = []\n",
    "    for year in years_list:\n",
    "        url = f'https://www.pro-football-reference.com/draft/{year}-combine.htm#combine'\n",
    "        html = requests.get(url).content\n",
    "        df_list = pd.read_html(html)\n",
    "        df = df_list[-1]\n",
    "\n",
    "        #drop rows with headers\n",
    "        df = df[df[\"Player\"] != \"Player\"]\n",
    "\n",
    "        #Rename Drafted NaN values to Undrafted\n",
    "        df['Drafted (tm/rnd/yr)'] = df['Drafted (tm/rnd/yr)'].fillna('Undrafted / 8th / 251st pick / 2018')\n",
    "        \n",
    "        class_list.append(df)\n",
    "        \n",
    "    if len(years_list)>1:   \n",
    "        df = pd.concat(class_list, axis = 0)\n",
    "        \n",
    "        #drop NAs now from draft class\n",
    "        #draft_class18 = draft_class18.dropna()\n",
    "        \n",
    "        df = df.drop(df[['College']], axis = 1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55df31c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import CSV training data\n",
    "draft_classes = scrape_combine(combine_years_list)\n",
    "draft_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1131edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_combine_stats(df):\n",
    "    df['Ht'] = df['Ht'].fillna('0-0')\n",
    "    \n",
    "    # Split the Height into feet and inches, then convert to numeric, \n",
    "    # and calculate BMI\n",
    "    ft_ = df['Ht'].apply(lambda x: x.split('-')[0])\n",
    "    in_ = df['Ht'].apply(lambda x: x.split('-')[-1])\n",
    "    ft_ = pd.to_numeric(ft_)\n",
    "    in_ = pd.to_numeric(in_)\n",
    "    wt_ = pd.to_numeric(df['Wt'])\n",
    "    # wt_ = draft_class18['Wt']\n",
    "    inches_ = (12*ft_) + in_\n",
    "    m = inches_ * 0.0254\n",
    "    m2 = m**2\n",
    "    kg = wt_ * 0.453592\n",
    "    df['Ht'] = inches_\n",
    "    df['BMI'] = kg/m2\n",
    "\n",
    "    \n",
    "    # Isolate just their draft pick\n",
    "    df['Draft Pick']= df['Drafted (tm/rnd/yr)'].apply(lambda x: x.split('/')[2])\n",
    "    # Extract only the numeric part\n",
    "    df['Draft Pick'] = df['Draft Pick'].str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "\n",
    "    # Isolate just their draft round\n",
    "    df['Draft Round']= df['Drafted (tm/rnd/yr)'].apply(lambda x: x.split('/')[1])\n",
    "    df['Draft Round'] = df['Draft Round'].str[1]\n",
    "    \n",
    "    # Isolate just their draft year\n",
    "    df['Draft Year']= df['Drafted (tm/rnd/yr)'].apply(lambda x: x.split('/')[3])\n",
    "    #df['Draft Year'] = df['Draft Year'].str[1]\n",
    "\n",
    "    # drop drafted column\n",
    "    df = df.drop(df[['Drafted (tm/rnd/yr)']], axis = 1)\n",
    "    \n",
    "    # isolate just wide receivers for now\n",
    "    df = df[df['Pos']== 'WR']\n",
    "\n",
    "    # mean impute combine stats\n",
    "    columns = ['Ht', 'Wt', '40yd', 'Vertical', 'Bench', 'Broad Jump', '3Cone', 'Shuttle','BMI']\n",
    "    for column in columns:\n",
    "        df[column] = pd.to_numeric(df[column])\n",
    "        df[column] = df[column].fillna(df[column].mean())\n",
    "        df[column] = round(df[column],2)\n",
    "        \n",
    "    # Create Player_ID\n",
    "    df['Player_ID'] = df['Player'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).replace(' ', '').lower())\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ba5a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combine_stats = clean_combine_stats(draft_classes)\n",
    "combine_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64e1fc1",
   "metadata": {},
   "source": [
    "## b. Scrape WR Prospect Grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f198fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I manually copied the draft grades from https://www.nfl.com/draft/tracker/prospects/wr/all-colleges/all-statuses/2024?page=3&sortField=gradeSort&sortIsAscending=false\n",
    "# They are in the google sheet below but I downloaded locally for ease\n",
    "# google sheet link: https://docs.google.com/spreadsheets/d/1-v-_LSCyjjCrK9H_XTodxq5SJI76wRWUb948AMG_2lM/edit?gid=50233396#gid=50233396\n",
    "def get_draft_grades(years_list):\n",
    "    class_list = []\n",
    "    for year in years_list:\n",
    "        df = pd.read_excel('WR Draft Grades.xlsx', sheet_name= year)\n",
    "        #drop rows with headers\n",
    "        df = df[df[\"Player\"] != \"Player\"]\n",
    "        #isolate columns wanted\n",
    "        df = df[['Player', 'Grade']]\n",
    "        df['Year'] = year\n",
    "        # fill in no grade with 0\n",
    "        df['Grade'] = df['Grade'].fillna(0)\n",
    "        # drop rows with null\n",
    "        df = df.dropna()\n",
    "        # # Isolate just their name\n",
    "        df['Player']= df['Player'].apply(lambda x: x.split('\\n')[0])\n",
    "        # Create Player_ID\n",
    "        df['Player_ID'] = df['Player'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).replace(' ', '').lower())\n",
    "\n",
    "\n",
    "        \n",
    "        class_list.append(df)\n",
    "        \n",
    "    if len(years_list)>1:   \n",
    "        df = pd.concat(class_list, axis = 0)\n",
    "        \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297edd5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "draft_grades = get_draft_grades(combine_years_list)\n",
    "draft_grades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ce03b",
   "metadata": {},
   "source": [
    "## c. Scrape Second Contract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ee91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_second_contracts():\n",
    "    # Import CSV training data, start with WR\n",
    "    url = 'https://overthecap.com/contract-history/wide-receiver'\n",
    "    html = requests.get(url).content\n",
    "    df_list = pd.read_html(html)\n",
    "    df = df_list[-1]\n",
    "    \n",
    "    # take most important columns\n",
    "    df = df[['Player','Year Signed','APY as % Of Cap At Signing']]\n",
    "    \n",
    "    # Sort the DataFrame by Player and Year Signed\n",
    "    df = df.sort_values(by=['Player', 'Year Signed'])\n",
    "\n",
    "    # Create a rank within each group of col1 based on col2\n",
    "    df['rank'] = df.groupby('Player')['Year Signed'].rank(method='first')\n",
    "\n",
    "    # Filter to keep only rows with rank == 2 (2nd lowest)\n",
    "    df = df[df['rank'] == 2]\n",
    "\n",
    "    # Drop the helper 'rank' column (optional)\n",
    "    df = df.drop(columns=['rank'])\n",
    "\n",
    "    # Reset the index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # convert APY as $ of Cap At Signing to decimal\n",
    "    df['APY as % Of Cap At Signing'] = df['APY as % Of Cap At Signing'].replace('%', '', regex=True).astype(float) / 100\n",
    "    \n",
    "    # create Player_ID\n",
    "    df['Player_ID'] = df['Player'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).replace(' ', '').lower())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f145275c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "second_contracts = scrape_second_contracts()\n",
    "second_contracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b2331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the mean and median of the column\n",
    "mean_value = second_contracts['APY as % Of Cap At Signing'].mean()\n",
    "median_value = second_contracts['APY as % Of Cap At Signing'].median()\n",
    "\n",
    "# Set the size of the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create a histogram with Seaborn\n",
    "sns.histplot(second_contracts['APY as % Of Cap At Signing'], kde=True, bins=10)\n",
    "\n",
    "# Add a vertical line for the mean value\n",
    "plt.axvline(mean_value, color='red', linestyle='--', label=f'Mean: {mean_value:.2f}')\n",
    "\n",
    "# Add a vertical line for the median value\n",
    "plt.axvline(median_value, color='blue', linestyle='--', label=f'Median: {median_value:.2f}')\n",
    "\n",
    "# Add the labels for the mean and median\n",
    "plt.text(mean_value + 0.5, 3, f'Mean: {mean_value:.2f}', color='red', fontsize=12)\n",
    "plt.text(median_value + 0.5, 3, f'Median: {median_value:.2f}', color='blue', fontsize=12)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of Wide Receiver Second Contracts', fontsize=16)\n",
    "plt.xlabel('APY as % of Cap at Signing', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "# Display the legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1474ee43",
   "metadata": {},
   "source": [
    "## d. Scrape Receiving Stats\n",
    "\n",
    "Get Receiving Stats from best season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV training data, start with WR\n",
    "def scrape_receiving_stats(years_list):\n",
    "    class_list = []\n",
    "    for year in years_list:\n",
    "        url = f'https://www.sports-reference.com/cfb/years/{year}-receiving.html'\n",
    "        html = requests.get(url).content\n",
    "        df_list = pd.read_html(html)\n",
    "        df = df_list[-1]\n",
    "        \n",
    "        class_list.append(df)\n",
    "        \n",
    "    if len(years_list)>1:   \n",
    "        df = pd.concat(class_list, axis = 0)\n",
    "        \n",
    "    # Set the column names to the second row (drop the first row of column headers)\n",
    "    df.columns = df.columns.get_level_values(1)\n",
    "\n",
    "    awards = df.Awards\n",
    "\n",
    "    df = df.iloc[:, :-6]\n",
    "\n",
    "    df['Awards'] = awards\n",
    "\n",
    "    # Get the column positions of 'Yds'\n",
    "    yds_columns = [i for i, col in enumerate(df.columns) if col == 'Yds']\n",
    "\n",
    "    # Rename the 'Yds' columns\n",
    "    df.columns.values[yds_columns[0]] = 'rec_yds'\n",
    "    df.columns.values[yds_columns[1]] = 'rush_yds'\n",
    "\n",
    "    # Get the column positions of 'Yds'\n",
    "    td_columns = [i for i, col in enumerate(df.columns) if col == 'TD']\n",
    "\n",
    "    # Rename the 'Yds' columns\n",
    "    df.columns.values[td_columns[0]] = 'rec_TD'\n",
    "    df.columns.values[td_columns[1]] = 'rush_TD'\n",
    "\n",
    "    # Create the 'award_count' column\n",
    "    df['award_count'] = df['Awards'].apply(lambda x: 0 if pd.isna(x) else len(x.split(',')))\n",
    "\n",
    "    # Remove asterisks from the 'Player' column\n",
    "    df['Player'] = df['Player'].str.replace('*', '', regex=False)\n",
    "    \n",
    "    # Create the 'years_played' column\n",
    "    df['years_played'] = df.groupby('Player')['Player'].transform('count')\n",
    "\n",
    "    # Sort the dataframe by 'Player' and 'rec_yds' to get the row with the highest 'rec_yds' for each player\n",
    "    df_sorted = df.sort_values(by=['Player', 'rec_yds'], ascending=[True, False])\n",
    "\n",
    "    # Drop duplicates based on the 'Player' column, keeping the row with the highest 'rec_yds'\n",
    "    df = df_sorted.drop_duplicates(subset='Player', keep='first')\n",
    "    \n",
    "    \n",
    "    # fill Y/A with 0\n",
    "    df['Y/A'] = df['Y/A'].fillna(0)\n",
    "    \n",
    "    \n",
    "    # create player_id\n",
    "    df['Player_ID'] = df['Player'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).replace(' ', '').lower())\n",
    "\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfbd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "college_stats = scrape_receiving_stats(college_years_list)\n",
    "college_stats.sort_values(by = 'Player').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99cf122",
   "metadata": {},
   "source": [
    "## e. Join the data and make model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78647ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(combine_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5fedf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_stats[combine_stats['Player_ID']== 'ajbrown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17273d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(college_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5801da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "college_stats[college_stats['Player_ID']== 'ajbrown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675cab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the joins\n",
    "df_merged = combine_stats.merge(college_stats, on=['Player_ID'], how='inner',suffixes=('', '_drop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdd8bf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da5f13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merged[df_merged['Player_ID']== 'ajbrown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b81b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the joins\n",
    "df_merged = df_merged.merge(draft_grades, on='Player_ID', how='inner',suffixes=('', '_drop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae61a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d2489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[df_merged['Player_ID']== 'ajbrown']\n",
    "df_merged = df_merged.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac31b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.merge(second_contracts, on='Player_ID', how='inner', suffixes=('', '_drop'))\n",
    "df_merged[['Year Signed','APY as % Of Cap At Signing']] = df_merged[['Year Signed','APY as % Of Cap At Signing']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd6592",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d4b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[df_merged['Player_ID']== 'ajbrown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca8592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_vars(df_merged):\n",
    "    \n",
    "    # Create the 'ideal_ht' column: 1 if Ht > 71 and < 75\n",
    "    df_merged['ideal_ht'] = np.where((df_merged['Ht'] > 71) & (df_merged['Ht'] < 75), 1, 0)\n",
    "\n",
    "    # Create the 'ideal_wt' column: 1 if Ht > 190 and < 216\n",
    "    df_merged['ideal_wt'] = np.where((df_merged['Wt'] > 185) & (df_merged['Wt'] < 216), 1, 0)\n",
    "\n",
    "    # Create the 'ideal_bmi' column: 1 if BMI > 25 and < 31\n",
    "    df_merged['ideal_bmi'] = np.where((df_merged['BMI'] > 25) & (df_merged['BMI'] < 31), 1, 0)\n",
    "\n",
    "    # Create the 'ideal_40' column: 1 if 40yd > 4.29 and < 4.6\n",
    "    df_merged['ideal_40'] = np.where((df_merged['40yd'] > 4.29) & (df_merged['40yd'] < 4.6), 1, 0)\n",
    "\n",
    "    # Create the 'ideal_shuttle' column: 1 if Shuttle < 4.3\n",
    "    df_merged['ideal_shuttle'] = np.where((df_merged['Shuttle'] < 4.55), 1, 0)\n",
    "\n",
    "    # Create 'ideal_all' if all ideal categories are met\n",
    "    df_merged['ideal_all'] = ((df_merged['ideal_ht'] == 1) & \n",
    "                       (df_merged['ideal_bmi'] == 1) & \n",
    "                       (df_merged['ideal_40'] == 1) & \n",
    "                       (df_merged['ideal_shuttle'] == 1)).astype(int)\n",
    "\n",
    "    #Create 'elite_production' column\n",
    "    df_merged['elite_prod'] = np.where((df_merged['rec_yds'] >= 1100 | (df_merged['rec_TD'] >= 10) | (df_merged['Rec'] >= 80)), 1, 0)\n",
    "\n",
    "    #Create 'td/rec'\n",
    "    df_merged['td/rec'] =np.where(df_merged['rec_TD'] > 0, df_merged['Rec'] / df_merged['rec_TD'], 0)\n",
    "\n",
    "    #Create 'rec/g'\n",
    "    df_merged['rec/g'] =np.where(df_merged['Rec'] > 0, df_merged['Rec'] / df_merged['G'], 0)\n",
    "\n",
    "    #bmi/shuttle\n",
    "    df_merged['bmi/shuttle'] = df_merged['BMI'] / df_merged['Shuttle']\n",
    "\n",
    "    #bmi/bench\n",
    "    df_merged['bmi/bench'] = df_merged['BMI'] / df_merged['Bench']\n",
    "\n",
    "    #bmi/40\n",
    "    df_merged['bmi/40'] = df_merged['BMI'] / df_merged['40yd']\n",
    "\n",
    "    #bmi/vertical\n",
    "    df_merged['bmi/vertical'] = df_merged['BMI'] / df_merged['Vertical']\n",
    "\n",
    "    # Create the 'H_win' column if won the heisman\n",
    "    # If the number is 1, set 'H_win' to 1\n",
    "    df_merged['Awards'] = df_merged['Awards'].fillna('None')\n",
    "    df_merged['H_win'] = df_merged['Awards'].apply(lambda x: 1 if re.search(r'H-(\\d+)', x) and int(re.search(r'H-(\\d+)', x).group(1)) == 1 else 0)\n",
    "\n",
    "    # Create dummy variables for the 'School' column\n",
    "#     df_schools = pd.get_dummies(df_merged['Conf'], prefix='Conf')\n",
    "\n",
    "    # Combine the original dataframe with the new dummy columns\n",
    "#     df_merged = pd.concat([df_merged, df_schools], axis=1)\n",
    "    \n",
    "    \n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b746cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = create_new_vars(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e14fcc",
   "metadata": {},
   "source": [
    "## Section 2. Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f82a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_vars = ['Player','Player_ID','Ht','Wt','40yd', 'Vertical',\n",
    "       'Broad Jump', '3Cone', 'Shuttle', 'BMI', 'Draft Pick', 'Grade',\n",
    "       'Draft Year', 'G', 'Rec', 'rec_yds', 'Y/R',\n",
    "       'rec_TD', 'Y/G']\n",
    "\n",
    "\n",
    "df_merged2 = df_merged[interesting_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the independent variables (X) and the dependent variable (Y)\n",
    "ind_vars = ['Vertical','Ht','Broad Jump', '3Cone', 'Shuttle', '40yd','BMI',\n",
    "            'Draft Round', 'Draft Year', 'Grade',\n",
    "            'rec_yds','Rec','Y/G','years_played', 'rec_TD', \n",
    "            'bmi/40', 'bmi/shuttle',\n",
    "#            'award_count','bmi/vertical',\n",
    "            \n",
    "            #dummy vars\n",
    "            'H_win',\n",
    "            'elite_prod',\n",
    "            'ideal_ht','ideal_bmi', 'ideal_40','ideal_shuttle']\n",
    "\n",
    "X = df_merged[ind_vars] # Independent variables\n",
    "y = df_merged['APY as % Of Cap At Signing']  # Dependent variable\n",
    "\n",
    "# Split data into training and test sets (optional, for validation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get the model coefficients (weights)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predictions:\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d32e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy metrics\n",
    "\n",
    "# R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe2b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance based on coefficients\n",
    "coefficients = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])\n",
    "\n",
    "# Sort the coefficients by the absolute value to find the most important features\n",
    "coefficients['Abs_Coefficient'] = coefficients['Coefficient'].abs()\n",
    "coefficients_sorted = coefficients.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Display the top 5 most important features\n",
    "top_5_features = coefficients_sorted.head(5)\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(top_5_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151fc0f",
   "metadata": {},
   "source": [
    "## Predict APY % for 10 Receivers that got large contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8168d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(df_merged[X.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feea88d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged2['Predicted APY as % of Cap'] = preds\n",
    "\n",
    "df_merged2['APY as % Of Cap At Signing'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c435100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by actual\n",
    "df_merged2.sort_values(by = 'APY as % Of Cap At Signing', ascending = False).reset_index(drop = True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by predicted\n",
    "df_merged2.sort_values(by = 'Predicted APY as % of Cap', ascending = False).reset_index(drop = True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177e29b1",
   "metadata": {},
   "source": [
    "## Section 3. Predict Contracts for 2021 through 2024 Draft Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e61f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#years_list = ['2021', '2022', '2023', '2024']\n",
    "college_years_list = ['2017','2018','2019','2020','2021','2022', '2023']\n",
    "combine_years_list = ['2021', '2022','2023','2024']\n",
    "\n",
    "\n",
    "# Import CSV training data\n",
    "draft_classes = scrape_combine(combine_years_list)\n",
    "combine_stats = clean_combine_stats(draft_classes)\n",
    "draft_grades = get_draft_grades(combine_years_list)\n",
    "combine_stats.sort_values(by = 'Player_ID').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11827069",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_stats[combine_stats['Player_ID']== 'jamarrchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8960669",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "college_stats = scrape_receiving_stats(college_years_list)\n",
    "college_stats.sort_values(by = 'Player_ID').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5764031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "college_stats[college_stats['Player_ID']== 'jamarrchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e3b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the joins\n",
    "new_wrs = combine_stats.merge(college_stats, on='Player_ID', how='inner', suffixes=('', '_drop')).merge(draft_grades, on = 'Player_ID', how = 'inner', suffixes=('', '_drop'))\n",
    "new_wrs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c885b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model vars\n",
    "X = create_new_vars(new_wrs)\n",
    "\n",
    "# create predictions, append on \n",
    "X = X[ind_vars]\n",
    "\n",
    "preds = model.predict(X)\n",
    "\n",
    "# Create prediction dataframe\n",
    "new_wrs = new_wrs[interesting_vars]\n",
    "\n",
    "new_wrs['Predicted APY as % of Cap'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d153d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wrs[new_wrs['Player_ID']== 'jamarrchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a19ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print receivers to be predicted as top paid\n",
    "new_wrs.sort_values(by = 'Predicted APY as % of Cap', ascending = False).reset_index(drop = True).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d03fe2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bec2e227",
   "metadata": {},
   "source": [
    "## Next Step: Try to account for the fact that receivers are overpaid\n",
    "\n",
    "additional helpful data like: X/Y/Z/F %, arm length, yards per route run, age, maybe add scouting report sentement analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
